import streamlit as st
import os
import requests
import time
import google.generativeai as genai

apply_global_style()
st.header("ğŸ§‘â€ğŸ’¼ AI å°è©±ç³»çµ±")

gemini_key = "AIzaSyBN5FU3Wk-DcFeRwINM9F6jBLwmS94chng"
client = genai.Client(api_key=gemini_key)

GITHUB_USER = "ChewyChloe"
GITHUB_REPO = "cpbl-project"
GITHUB_FOLDER = "AI_RAG"
GITHUB_API_URL = f"https://api.github.com/repos/{GITHUB_USER}/{GITHUB_REPO}/contents/{GITHUB_FOLDER}"
TARGET_STORE_NAME = "CPBL_Scout_Knowledge_v6"

@st.cache_resource(show_spinner="åŒæ­¥ GitHub çŸ¥è­˜åº«")
def auto_initialize_rag(_client):
    store = None

    try:
        for s in _client.file_search_stores.list():
            if s.display_name == TARGET_STORE_NAME:
                store = s
                break
    except Exception:
        pass

    if not store:
        try:
            store = _client.file_search_stores.create(
                config={'display_name': TARGET_STORE_NAME}
            )
        except Exception as e:
            print(f"å»ºç«‹ Store å¤±æ•—: {e}")
            return None

    existing_files = []
    try:
        pager = _client.file_search_stores.list_files(file_search_store_name=store.name)
        existing_files = list(pager)
    except:
        pass

    if len(existing_files) == 0:
        try:
            res = requests.get(GITHUB_API_URL)
            if res.status_code == 200:
                files_metadata = res.json()
                for i, file_info in enumerate(files_metadata):
                    original_name = file_info['name']
                    lower_name = original_name.lower()

                    if lower_name.endswith(('.pdf', '.txt', '.docx')):
                        f_res = requests.get(file_info['download_url'])

                        if f_res.status_code == 200:
                            safe_ext = ".pdf" if ".pdf" in lower_name else ".txt" if ".txt" in lower_name else ".docx"
                            safe_temp_name = f"temp_doc_{i}{safe_ext}"

                            with open(safe_temp_name, "wb") as f:
                                f.write(f_res.content)

                            if os.path.getsize(safe_temp_name) > 0:
                                mime_type = "application/pdf"
                                if safe_ext == ".txt": mime_type = "text/plain"
                                elif safe_ext == ".docx": mime_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"

                                try:
                                    _client.file_search_stores.upload_to_file_search_store(
                                        file=safe_temp_name,
                                        file_search_store_name=store.name,
                                        config={
                                            'display_name': original_name,
                                            'mime_type': mime_type
                                        }
                                    )
                                    time.sleep(1)
                                except Exception as e:
                                    print(f"ä¸Šå‚³å¤±æ•—: {e}")

                            if os.path.exists(safe_temp_name):
                                os.remove(safe_temp_name)
        except Exception as e:
            print(f"GitHub åŒæ­¥éŒ¯èª¤: {e}")

    return store.name if store else None

# åˆå§‹åŒ–
store_name = auto_initialize_rag(client)

if not store_name:
    st.error("âš ï¸ çŸ¥è­˜åº«åˆå§‹åŒ–å¤±æ•—ã€‚")
    st.stop()

# å°è©±ä»‹é¢
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("è«‹æ•™å°ˆæ¥­çƒæ¢åˆ†æ..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                response = client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=prompt,
                    config={
                        "tools": [{
                            "file_search": {
                                "file_search_store_names": [store_name]
                            }
                        }],
                        "system_instruction": """
                        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ£’çƒç ”ç©¶å“¡ã€‚
                        1. ç•¶ä½¿ç”¨è€…å•åˆ°å…·é«”æ•¸æ“šæˆ–çƒæ¢å ±å‘Šæ™‚ï¼Œè«‹å„ªå…ˆåƒè€ƒã€ŒçŸ¥è­˜åº«ã€ä¸­çš„æª”æ¡ˆå›ç­”ã€‚
                        2. å¦‚æœçŸ¥è­˜åº«ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œæˆ–è€…ä½¿ç”¨è€…æ˜¯åœ¨å•ä¸€èˆ¬æ£’çƒè¦å‰‡ã€æ­·å²æˆ–é–’èŠï¼Œè«‹å–„ç”¨ä½ çš„ã€Œé€šç”¨æ£’çƒçŸ¥è­˜ã€ç›´æ¥å›ç­”ã€‚
                        3. å›ç­”æ™‚è«‹ä¿æŒå°ˆæ¥­ã€å®¢è§€ï¼Œçµ•å°ä¸å¯æåŠ"è³‡æ–™åº«"ã€"æ ¹æ“šæˆ‘å€‘æ‰‹é‚Šçš„è³‡æ–™"æˆ–"æ ¹æ“š..."ã€‚
                        4. èªæ°£è¼•é¬†ä¸åš´è‚…
                        5. åå­—ï¼šBrian
                        """
                    }
                )
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})

            except Exception as e:
                st.error(f"ç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
